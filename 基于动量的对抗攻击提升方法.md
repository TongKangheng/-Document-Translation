<h1 align="center">基于动量的对抗攻击提升方法</h1>

$$
\begin{gather}
Yinpeng \space Dong^1, Fangzhou \space Liao^1, Tianyu \space Pang^1, Hang \space Su^1, Jun \space Zhu^{1*}, Xiaolin \space Hu^1, Jianguo \space Li^2\\
{}^1Department \space of \space Computer \space Science \space and \space Technology, Tsinghua \space Lab \space of \space Brain \space and \space Intelligence\\
{}^1Beijing \space National \space Research \space Center \space for \space Information \space Science \space and \space Technology, BNRist \space Lab\\
{}^2Intel \space Labs \space China\\
\{dyp17, liaofz13, pty17\}@mails.tsinghua.edu.cn,\{suhangss,dcszj,xlhu\}@mail.tsinghua.edu.cn,jianguo.li@intel.com
\end{gather}
$$

<h1 align="center">摘要</h1>

​		当面对对抗样本时，深度神经网络是脆弱的，潜在的严重后果给这些算法造成了安全问题。在深度学习模型部署之前，对抗攻击是一种评估它们鲁棒性的重要代表。然而，大多数已有的对抗攻击只能以较低的成功率欺骗黑盒模型。为了解决这个问题，我们提出了一大类基于动量的迭代算法来增强对抗攻击。通过将动量项整合到攻击的迭代过程中，我们的方法可以稳定更新方向，并在迭代过程中摆脱不良的局部最大值，从而产生更具可移植性的对抗样本。为了进一步提高黑盒攻击的成功率，我们将动量迭代算法应用于一组模型，并证明经过对抗训练的、具有强大防御能力的模型也容易受到我们的黑盒攻击。我们希望所提出的方法将作为评估各种深度模型和防御方法的鲁棒性的基准。通过这种方法，我们在NIPS 2017非针对性对抗攻击和针对性对抗攻击比赛中获得了第一名。

# 1、介绍

​		由于面对对抗样本[23，5]时的脆弱性，深度神经网络（DNN）受到了挑战，这些样本是通过向合法样本中添加人类无法察觉的细微噪声来制作的，但它们会为模型输出提供攻击者所需的不准确预测。对抗样本的生成获得了越来越多的关注，因为它有助于在启动模型之前确定其脆弱性。此外，对抗样本还通过提供更多样化的训练数据[5，10]来促进各种DNN算法获得鲁棒性。

​		知道了给定模型的结构和参数，许多方法都能以白盒方式成功生成对抗样本，包括基于优化的方法，例如盒约束L-BFGS [23]，基于单步梯度的方法，例如快速梯度符号[5]和基于梯度的方法的迭代变体[9]。通常，对抗样本的一个更严重的问题是它们的良好可移植性[23，12，14]，即为一种模型设计的对抗样本对于其他模型仍然具有对抗性，因此使黑盒攻击在实际应用中切实可行并构成真正的安全问题。可移植性的现象是由于不同的机器学习模型在一个数据点周围学习了类似的决策边界这一事实，使得为一种模型设计的对抗样本对其他模型有效。

​		但是，现有的攻击方法在攻击黑盒模型时效率低下，尤其是对于具有防御机制的模型。例如，整体对抗训练[24]显著提高了深度神经网络的鲁棒性，并且大多数现有方法无法以黑盒方式成功攻击它们。这个事实很大程度上归因于攻击能力和可移植性之间的权衡。特别是，通过基于优化的迭代方法生成的对抗样本具有较差的可移植性[10]，因此使黑盒攻击的有效性降低。另一方面，基于梯度的单步方法会产生更加可移植的对抗样本，但是对于白盒模型而言，它们的成功率通常较低[10]，从而使其对黑盒攻击无效。考虑到实际黑盒攻击的困难，Papernot等人 [16]使用自适应查询来训练替代模型以完全表征目标模型的行为，从而将黑盒攻击转变为白盒攻击。但是，它需要目标模型给出的完全预测置信度和大量查询，尤其是对于大型数据集（例如ImageNet [19]）。这样的要求在实际应用中是不切实际的。因此，我们考虑如何在不知道其架构和参数的情况下，有效地攻击黑盒模型，而且无需查询。

​		在本文中，我们提出了一系列基于动量迭代梯度的方法，以提高生成的对抗样本的成功率。除了基于迭代梯度的方法，该方法使用梯度来迭代扰动输入以最大化损失函数[5]，基于动量的方法还可以在迭代过程中沿损失函数的梯度方向累积速度矢量，目的是稳定更新方向和从不良的局部最大值中逃脱。我们表明，由动量迭代方法生成的对抗示例在白盒和黑盒攻击中均具有较高的成功率。所提出的方法减轻了白盒攻击与可传递性之间的折衷，并且比单步方法[5]和香草迭代方法[9]发挥了更强的攻击算法的作用。

